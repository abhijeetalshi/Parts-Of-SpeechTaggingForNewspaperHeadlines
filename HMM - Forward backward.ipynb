{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter_B-PER Blackburn_I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUSSELS_B-LOC 1996-08-22_O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_O European_B-ORG Commission_I-ORG said_O o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany_B-LOC 's_O representative_O to_O the_O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_O We_O do_O n't_O support_O any_O such_O reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines\n",
       "0                        Peter_B-PER Blackburn_I-PER\n",
       "1                        BRUSSELS_B-LOC 1996-08-22_O\n",
       "2  The_O European_B-ORG Commission_I-ORG said_O o...\n",
       "3  Germany_B-LOC 's_O representative_O to_O the_O...\n",
       "4  _O We_O do_O n't_O support_O any_O such_O reco..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('trainwords.txt', sep='\\n', names = ['headlines'], header = 0) \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = np.genfromtxt(\"trainwords.txt\", delimiter= '\\n',dtype= None, unpack = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning index to words and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['*OOV*', '\"', '$', ..., 'yr', 'yuan', 'zinc'],\n",
       "      dtype='|S24')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ind_X = np.genfromtxt(\"index_to_word.txt\",delimiter= '\\n',dtype= None, unpack = True) \n",
    "f_ind_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG',\n",
       "       'I-PER', 'O'],\n",
       "      dtype='|S6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ind_Y = np.genfromtxt(\"index_to_tag.txt\",delimiter= '\\n',dtype= None, unpack = True) \n",
    "f_ind_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using dictionaries to store the index of words and tags\n",
    "d1 = {} \n",
    "d2 = {} \n",
    "d3 = {} \n",
    "d4 = {} \n",
    "\n",
    "for i in range(len(f_ind_X)):\n",
    "    d1[f_ind_X[i]] = i+1\n",
    "    d3[i+1] = f_ind_X[i]\n",
    "    \n",
    "for i in range(len(f_ind_Y)):    \n",
    "    d2[f_ind_Y[i]] = i+1\n",
    "    d4[i+1] = f_ind_Y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating the words and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lw = []\n",
    "for j in range(len(f)):\n",
    "    words1 = f[j].split()\n",
    "    lw.append(len(words1))\n",
    "           \n",
    "X = np.zeros((len(f),max(lw)))\n",
    "Y = np.zeros((len(f),max(lw)))\n",
    "\n",
    "for j in range(len(f)):\n",
    "    words1 = f[j].split()\n",
    "    for i in range(len(words1)): \n",
    "        words2 = np.array(words1[i].split('_'))\n",
    "        X[j][i] = d1.get(words2[0])\n",
    "        Y[j][i] = d2.get(words2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the initialization probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = np.zeros(len(d2))\n",
    "\n",
    "Np = []\n",
    "for i in range(len(d2)):\n",
    "    Np.append(Y[:,0].tolist().count(i+1) + 1)\n",
    "\n",
    "for i in range(len(d2)):\n",
    "    pi[i] = Np[i]/sum(Np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating emission and transition probabilities probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nb = np.zeros((len(d2),len(d1)))\n",
    "\n",
    "Na = np.zeros((len(d2),len(d2)))\n",
    "\n",
    "for j in range(len(f)):\n",
    "    words1 = f[j].split()\n",
    "    for i in range(len(words1)): \n",
    "        words2 = np.array(words1[i].split('_'))\n",
    "        X[j][i] = d1.get(words2[0])\n",
    "        Y[j][i] = d2.get(words2[1])\n",
    "        Nb[int(Y[j][i])-1][int(X[j][i])-1] = Nb[int(Y[j][i])-1][int(X[j][i])-1] + 1 \n",
    "        if(i<len(words1)-1):\n",
    "            Na[int(Y[j][i])-1][int(Y[j][i+1])-1] = Na[int(Y[j][i])-1][int(Y[j][i+1])-1] + 1\n",
    "        else:\n",
    "            continue \n",
    "        \n",
    "Nb = Nb + np.ones((len(d2),len(d1))) \n",
    "\n",
    "b = np.zeros((len(d2),len(d1))) \n",
    "\n",
    "b = (Nb.T / sum(Nb.T)).T\n",
    "\n",
    "Na = Na + np.ones((len(d2),len(d2)))\n",
    "\n",
    "a = np.zeros((len(d2),len(d2))) \n",
    "\n",
    "a = (Na.T / sum(Na.T)).T\n",
    "\n",
    "A = a   #Transition probabilites\n",
    "B = b   #Emission probabilities \n",
    "PI = pi #Initialization probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(pi,a,b,i):\n",
    "    f_test = np.genfromtxt(\"testwords.txt\",delimiter= '\\n',dtype= None, unpack = True)    \n",
    "    f_test = f_test[i]\n",
    "    f_test = f_test.tolist()\n",
    "    words1_ = f_test.split()\n",
    "    X1 = np.zeros((1,len(words1_)))\n",
    "    Y1 = np.zeros((1,len(words1_)))\n",
    "    \n",
    "    words20 = [] \n",
    "    for i in range(len(words1_)):\n",
    "        words2_ = words1_[i].split('_')\n",
    "        X1[0][i] = d1.get(words2_[0])\n",
    "        Y1[0][i] = d2.get(words2_[1])\n",
    "        words20.append(words2_[0])       \n",
    "    alpha = pi*b[:,int(X1[0][0])-1] \n",
    "    alpha = np.matrix(alpha) \n",
    "    alpha = alpha.T \n",
    "    a = np.matrix(a) \n",
    "    b = np.matrix(b) \n",
    "    ALPHA = np.array(alpha) \n",
    "    for i in range(1,len(words1_)): \n",
    "        alpha = np.multiply(b[:,int(X1[0][i]-1)],(a.T*alpha))\n",
    "        ALPHA = np.hstack((ALPHA,np.array(alpha)))\n",
    "        \n",
    "    beta = np.ones((len(d2),1)) \n",
    "    \n",
    "    beta = np.matrix(beta) \n",
    "    \n",
    "    a = np.matrix(a) \n",
    "    \n",
    "    BETA = np.array(beta)\n",
    "    for i in range(1,len(words1_)):\n",
    "        beta = a*np.multiply(b[:,int(X1[0][len(words1_)-i]-1)],beta)\n",
    "        BETA = np.hstack((BETA,np.array(beta)))\n",
    "    BETA = np.flip(BETA,1)                                   \n",
    "    prob = ALPHA*BETA\n",
    "        \n",
    "    pred = []\n",
    "    \n",
    "    for i in range(len(words1_)):\n",
    "        a = np.argmax(prob[:,i])\n",
    "        pred1 = d4[a+1]\n",
    "        join_list = [words20[i],pred1]\n",
    "        pred.append('_'.join(join_list))\n",
    "        #pred.append(d4[np.argmax(prob[:,i])+1])\n",
    "    return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_test1 = np.genfromtxt(\"testwords.txt\",delimiter= '\\n',dtype= None, unpack = True)\n",
    "output = open(\"output1.txt\",'w')  \n",
    "for i in range(10):\n",
    "    arrp = prediction(PI,A,B,i) \n",
    "    for j in range(len(arrp)): \n",
    "        ant = arrp[j] \n",
    "        if(j == len(arrp)-1): \n",
    "            #print('{}\\n'.format(ant)) \n",
    "            output.write('{}\\n'. format(ant))  \n",
    "        else:\n",
    "            #print('{}'.format(ant)) \n",
    "            output.write('{} '. format(ant)) \n",
    "output.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for first 10 data from test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'CRICKET_O -_O *OOV*_O *OOV*_O *OOV*_O AT_O TOP_O AFTER_O *OOV*_O *OOV*_O ._O',\n",
       "       'LONDON_B-LOC 1996-08-30_O',\n",
       "       'West_B-LOC Indian_I-ORG all-rounder_O Phil_B-PER Simmons_I-PER took_O four_O for_O 38_O on_O Friday_O as_O Leicestershire_B-ORG beat_O Somerset_B-ORG by_O an_O innings_O and_O 39_O runs_O in_O two_O days_O to_O take_O over_O at_O the_O head_O of_O the_O county_O championship_O ._O',\n",
       "       'Their_O stay_O on_O top_O ,_O though_O ,_O may_O be_O *OOV*_O as_O title_O rivals_O Essex_B-ORG ,_O Derbyshire_B-ORG and_O Surrey_B-ORG all_O closed_O in_O on_O victory_O while_O Kent_B-ORG made_O up_O for_O lost_O time_O in_O their_O *OOV*_O match_O against_O Nottinghamshire_B-ORG ._O',\n",
       "       'After_O bowling_O Somerset_B-ORG out_O for_O 83_O on_O the_O opening_O morning_O at_O *OOV*_O Road_O ,_O Leicestershire_B-ORG extended_O their_O first_O innings_O by_O 94_O runs_O before_O being_O bowled_O out_O for_O *OOV*_O with_O England_B-LOC *OOV*_O Andy_B-PER *OOV*_I-PER taking_O three_O for_O 83_O ._O',\n",
       "       '*OOV*_O by_O *OOV*_O ,_O Somerset_B-ORG got_O a_O solid_O start_O to_O their_O second_O innings_O before_O Simmons_O stepped_O in_O to_O *OOV*_O them_O out_O for_O *OOV*_O ._O',\n",
       "       'Essex_B-ORG ,_O however_O ,_O look_O certain_O to_O *OOV*_O their_O top_O spot_O after_O *OOV*_B-PER Hussain_I-PER and_O Peter_B-PER *OOV*_I-PER gave_O them_O a_O firm_O grip_O on_O their_O match_O against_O Yorkshire_B-ORG at_O Headingley_B-LOC ._O',\n",
       "       \"Hussain_B-PER ,_O considered_O surplus_O to_O England_B-LOC 's_O one-day_O requirements_O ,_O struck_O *OOV*_O ,_O his_O first_O championship_O century_O of_O the_O season_O ,_O as_O Essex_B-ORG reached_O *OOV*_O and_O took_O a_O first_O innings_O lead_O of_O 82_O ._O\",\n",
       "       'By_O the_O close_O Yorkshire_B-ORG had_O turned_O that_O into_O a_O *OOV*_O advantage_O but_O *OOV*_O *OOV*_O had_O *OOV*_O their_O hopes_O ,_O taking_O four_O for_O 24_O in_O 48_O balls_O and_O leaving_O them_O hanging_O on_O *OOV*_O for_O five_O and_O praying_O for_O rain_O ._O',\n",
       "       'At_O the_O Oval_B-LOC ,_O Surrey_B-ORG captain_O Chris_B-PER Lewis_I-PER ,_O another_O man_O *OOV*_O by_O England_B-LOC ,_O continued_O to_O silence_O his_O critics_O as_O he_O followed_O his_O four_O for_O 45_O on_O Thursday_O with_O 80_O not_O out_O on_O Friday_O in_O the_O match_O against_O Warwickshire_B-ORG ._O',\n",
       "       'Essex_B-LOC reached_B-LOC *OOV*_B-LOC and_B-LOC took_B-LOC a_B-LOC first_B-LOC innings_B-LOC lead_B-LOC of_B-LOC 82_B-LOC ._B-LOC',\n",
       "       'By_B-LOC the_B-LOC close_B-LOC Yorkshire_B-LOC had_B-LOC turned_B-LOC that_B-LOC into_B-LOC a_B-LOC *OOV*_B-LOC advantage_B-LOC but_B-LOC *OOV*_B-LOC *OOV*_B-LOC had_B-LOC *OOV*_B-LOC their_B-LOC hopes_B-LOC ,_B-LOC taking_B-LOC four_B-LOC for_B-LOC 24_B-LOC in_B-LOC 48_B-LOC balls_B-LOC and_B-LOC leaving_B-LOC them_B-LOC hanging_B-LOC on_B-LOC *OOV*_B-LOC for_B-LOC five_B-LOC and_B-LOC praying_B-LOC for_B-LOC rain_B-LOC ._B-LOC',\n",
       "       'At_B-LOC the_B-LOC Oval_B-LOC ,_B-LOC Surrey_B-LOC captain_B-LOC Chris_B-LOC Lewis_B-LOC ,_B-LOC another_B-LOC man_B-LOC *OOV*_B-LOC by_B-LOC England_B-LOC ,_B-LOC continued_B-LOC to_B-LOC silence_B-LOC his_B-LOC critics_B-LOC as_B-LOC he_B-LOC followed_B-LOC his_B-LOC four_B-LOC for_B-LOC 45_B-LOC on_B-LOC Thursday_B-LOC with_B-LOC 80_B-LOC not_B-LOC out_B-LOC on_B-LOC Friday_B-LOC in_B-LOC the_B-LOC match_B-LOC against_B-LOC Warwickshire_B-LOC ._B-LOC'],\n",
       "      dtype='|S457')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.genfromtxt(\"output.txt\",delimiter= '\\n',dtype= None, unpack = True) \n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
